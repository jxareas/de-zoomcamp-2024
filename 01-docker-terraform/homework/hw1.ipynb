{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c6178d1111eff5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question 1. Knowing docker tags\n",
    "\n",
    "Run the command to get information on Docker \n",
    "\n",
    "```docker --help```\n",
    "\n",
    "Now run the command to get help on the \"docker build\" command:\n",
    "\n",
    "```docker build --help```\n",
    "\n",
    "Do the same for \"docker run\".\n",
    "\n",
    "**Which tag has the following text?** - *Automatically remove the container when it exits* \n",
    "\n",
    "- `--delete`\n",
    "- `--rc`\n",
    "- `--rmc`\n",
    "- <font color='red'><b>`--rm`</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b510ed57db9caa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question 2. Understanding docker first run \n",
    "\n",
    "Run docker with the python:3.9 image in an interactive mode and the entrypoint of bash.\n",
    "Now check the python modules that are installed ( use ```pip list``` ). \n",
    "\n",
    "**What is version of the package *wheel* ?**\n",
    "\n",
    "- <font color='red'><b>0.42.0</b></font>\n",
    "- 1.0.0\n",
    "- 23.0.1\n",
    "- 58.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f0a68a1a6ff266",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare Postgres\n",
    "\n",
    "Run Postgres and load data as shown in the videos\n",
    "We'll use the green taxi trips from September 2019:\n",
    "\n",
    "```wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-09.csv.gz```\n",
    "\n",
    "You will also need the dataset with zones:\n",
    "\n",
    "```wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv```\n",
    "\n",
    "Download this data and put it into Postgres (with jupyter notebooks or with a pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b839d84fb3b2c1c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T05:25:14.250253400Z",
     "start_time": "2024-02-05T05:24:08.000054200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk, took 14.048 second\n",
      "Inserted another chunk, took 14.703 second\n",
      "Inserted another chunk, took 15.139 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jxareas\\AppData\\Local\\Temp\\ipykernel_18232\\2948968149.py:16: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk, took 13.611 second\n",
      "Inserted another chunk, took 5.938 second\n",
      "Finished ingesting data into the postgres database\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from time import time\n",
    "\n",
    "url = \"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-09.csv.gz\"\n",
    "\n",
    "engine = create_engine('postgresql://root:root@localhost:5431/ny_taxi')\n",
    "\n",
    "df_iter = pd.read_csv(url, iterator=True, chunksize=100_000)\n",
    "\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "        t_start = time()\n",
    "\n",
    "        df = next(df_iter)\n",
    "\n",
    "        df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime'])\n",
    "        df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime'])\n",
    "\n",
    "        df.to_sql(name='green_taxi_data', con=engine, if_exists='append')\n",
    "\n",
    "        t_end = time()\n",
    "\n",
    "        print('Inserted another chunk, took %.3f second' % (t_end - t_start))\n",
    "\n",
    "    except StopIteration:\n",
    "        print(\"Finished ingesting data into the postgres database\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e67cd2c622e9a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question 3. Count records \n",
    "\n",
    "**How many taxi trips were totally made on September 18th 2019?**\n",
    "\n",
    "Tip: started and finished on 2019-09-18. \n",
    "\n",
    "Remember that `lpep_pickup_datetime` and `lpep_dropoff_datetime` columns are in the format timestamp (date and hour+min+sec) and not in date.\n",
    "\n",
    "- 15767\n",
    "- <font color='red'><b>15612</b></font>\n",
    "- 15859\n",
    "- 89009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764acb81209afed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question 4. Longest trip for each day\n",
    "\n",
    "**Which was the pick up day with the longest trip distance?**\n",
    "Use the pick up time for your calculations.\n",
    "\n",
    "Tip: For every trip on a single day, we only care about the trip with the longest distance. \n",
    "\n",
    "Answer: \n",
    "```postgresql\n",
    "SELECT CAST(lpep_pickup_datetime AS DATE), MAX(trip_distance) AS max_trip_distance FROM green_taxi_data\n",
    "GROUP BY CAST(lpep_pickup_datetime AS DATE)\n",
    "ORDER BY max_trip_distance DESC\n",
    "limit 10\n",
    "```\n",
    "\n",
    "- 2019-09-18\n",
    "- 2019-09-16\n",
    "- <font color='red'><b>2019-09-26</b></font>\n",
    "- 2019-09-21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f89236ce4dd7952",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question 5. Three biggest pick up Boroughs\n",
    "\n",
    "Consider lpep_pickup_datetime in '2019-09-18' and ignoring Borough has Unknown\n",
    "\n",
    "Which were the 3 pick up Boroughs that had a sum of total_amount superior to 50000?\n",
    " \n",
    "Answer: \n",
    "```postgresql\n",
    "SELECT z.\"Borough\", ROUND(SUM(total_amount)::numeric, 2) AS total_amount_sum FROM green_taxi_data gtd\n",
    "INNER JOIN zones z ON gtd.\"PULocationID\" = z.\"LocationID\"\n",
    "WHERE CAST(lpep_pickup_datetime AS DATE) = '2019-09-18'\n",
    "GROUP BY(z.\"Borough\")\n",
    "ORDER BY total_amount_sum DESC\n",
    "```\n",
    "\n",
    "- <font color='red'><b>\"Brooklyn\" \"Manhattan\" \"Queens\"</b></font>\n",
    "- \"Bronx\" \"Brooklyn\" \"Manhattan\"\n",
    "- \"Bronx\" \"Manhattan\" \"Queens\" \n",
    "- \"Brooklyn\" \"Queens\" \"Staten Island\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c185585dd6ca35",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question 6. Largest tip\n",
    "\n",
    "For the passengers picked up in September 2019 in the zone name Astoria which was the drop off zone that had the largest tip?\n",
    "We want the name of the zone, not the id.\n",
    "\n",
    "Note: it's not a typo, it's `tip` , not `trip`\n",
    "\n",
    "Answer:\n",
    "```postgresql\n",
    "select dropoff.\"Zone\", MAX(tip_amount) AS max_tip_amount\n",
    "from green_taxi_data gtd\n",
    "         inner join zones pickup ON gtd.\"PULocationID\" = pickup.\"LocationID\"\n",
    "         inner join zones dropoff on gtd.\"DOLocationID\" = dropoff.\"LocationID\"\n",
    "where pickup.\"Zone\" LIKE 'Astoria' AND DATE_TRUNC('month', gtd.lpep_pickup_datetime) = '2019-09-01'::date\n",
    "group by dropoff.\"Zone\"\n",
    "order by max_tip_amount DESC\n",
    "LIMIT 1;\n",
    "```\n",
    "\n",
    "- Central Park\n",
    "- Jamaica\n",
    "- <font color='red'><b>JFK Airport</b></font>\n",
    "- Long Island City/Queens Plaza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53e53e3ee5e7d4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Terraform\n",
    "\n",
    "In this section homework we'll prepare the environment by creating resources in GCP with Terraform.\n",
    "\n",
    "In your VM on GCP/Laptop/GitHub Codespace install Terraform. \n",
    "Copy the files from the course repo\n",
    "[here](https://github.com/DataTalksClub/data-engineering-zoomcamp/tree/main/01-docker-terraform/1_terraform_gcp/terraform) to your VM/Laptop/GitHub Codespace.\n",
    "\n",
    "Modify the files as necessary to create a GCP Bucket and Big Query Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2948985de734baf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Question 7. Creating Resources\n",
    "\n",
    "After updating the main.tf and variable.tf files run:\n",
    "\n",
    "```\n",
    "terraform apply\n",
    "```\n",
    "\n",
    "Paste the output of this command into the homework submission form."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learner",
   "language": "python",
   "name": "deep-learner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
